{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11957,"sourceType":"datasetVersion","datasetId":8542},{"sourceId":36545,"sourceType":"datasetVersion","datasetId":1309},{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# Basic setup\nimport os, re, html, json, random\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\n# Set seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:20:09.128828Z","iopub.execute_input":"2025-08-24T08:20:09.129049Z","iopub.status.idle":"2025-08-24T08:20:15.688223Z","shell.execute_reply.started":"2025-08-24T08:20:09.129027Z","shell.execute_reply":"2025-08-24T08:20:15.687531Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# %% [code]\n# Load IMDB Sentiment Dataset\nimdb_path = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\ndf = pd.read_csv(imdb_path).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\ntrain_df, test_df = torch.utils.data.random_split(df, [40000, 10000])\nprint(\"IMDB Sentiment shape:\", df.shape)\n\n# Load Focused Reddit Sarcasm Dataset\nreddit_path = \"/kaggle/input/sarcasm/train-balanced-sarcasm.csv\"\nsarcasm_df = pd.read_csv(reddit_path)\nsarcasm_df.rename(columns={\"comment\": \"text\", \"label\": \"label\"}, inplace=True)\nsarcasm_df.dropna(subset=['text', 'label'], inplace=True)\nsarcasm_df['text'] = sarcasm_df['text'].astype(str)\nsarcasm_df['label'] = sarcasm_df['label'].astype(int)\nsarcasm_df = sarcasm_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n\n# Split the sarcasm data\nfrom sklearn.model_selection import train_test_split\ntrain_sarc, test_sarc = train_test_split(\n    sarcasm_df, test_size=0.2, random_state=SEED, stratify=sarcasm_df[\"label\"]\n)\nprint(\"Focused Sarcasm shape:\", sarcasm_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:20:51.701204Z","iopub.execute_input":"2025-08-24T08:20:51.701472Z","iopub.status.idle":"2025-08-24T08:21:03.249704Z","shell.execute_reply.started":"2025-08-24T08:20:51.701451Z","shell.execute_reply":"2025-08-24T08:21:03.249079Z"}},"outputs":[{"name":"stdout","text":"IMDB Sentiment shape: (50000, 2)\nFocused Sarcasm shape: (1010771, 10)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# %% [code]\ndef clean_text(t: str) -> str:\n    t = html.unescape(str(t))\n    t = re.sub(r\"<[^>]+>\", \" \", t)                  # remove HTML\n    t = re.sub(r\"[^a-zA-Z\\\\s']\", \" \", t)             # keep letters & apostrophes\n    return re.sub(r\"\\\\s+\", \" \", t).strip().lower()\n\n_tok_pat = re.compile(r\"[a-z']{2,}\")\ndef tokenize(text):\n    return _tok_pat.findall(clean_text(text))\n\n# IMDB tokens (1 = positive)\ntrain_tokens = [tokenize(t) for t in train_df.dataset['review'].iloc[train_df.indices]]\ntest_tokens  = [tokenize(t) for t in test_df.dataset['review'].iloc[test_df.indices]]\ntrain_labels = (train_df.dataset['sentiment'].iloc[train_df.indices].values == \"positive\").astype(np.float32)\ntest_labels  = (test_df.dataset['sentiment'].iloc[test_df.indices].values == \"positive\").astype(np.float32)\n\n# Sarcasm tokens (1 = sarcastic)\ntrain_sarc_tokens = [tokenize(t) for t in train_sarc[\"text\"].tolist()]\ntest_sarc_tokens  = [tokenize(t) for t in test_sarc[\"text\"].tolist()]\ntrain_sarc_labels = train_sarc[\"label\"].astype(np.float32).values\ntest_sarc_labels  = test_sarc[\"label\"].astype(np.float32).values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:21:17.683840Z","iopub.execute_input":"2025-08-24T08:21:17.684262Z","iopub.status.idle":"2025-08-24T08:21:34.906379Z","shell.execute_reply.started":"2025-08-24T08:21:17.684230Z","shell.execute_reply":"2025-08-24T08:21:34.905553Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# %% [code]\nPAD, UNK = \"<pad>\", \"<unk>\"\nmin_freq = 5\n\n# Build vocab from both training sets\nall_tokens = train_tokens + train_sarc_tokens\nctr = Counter(w for toks in all_tokens for w in toks)\nvocab_words = [w for w,c in ctr.items() if c >= min_freq]\n\nword_to_idx = {PAD:0, UNK:1}\nfor w in vocab_words:\n    word_to_idx[w] = len(word_to_idx)\n\nidx_to_word = {i:w for w,i in word_to_idx.items()}\npad_idx, unk_idx = word_to_idx[PAD], word_to_idx[UNK]\nvocab_size = len(word_to_idx)\nprint(\"Combined Vocab size:\", vocab_size)\n\n# Numericalize all datasets\ndef numericalize(toks):\n    return torch.tensor([word_to_idx.get(w, unk_idx) for w in toks], dtype=torch.long)\n\ntrain_ids = [numericalize(t) for t in train_tokens]\ntest_ids  = [numericalize(t) for t in test_tokens]\ntrain_sarc_ids = [numericalize(t) for t in train_sarc_tokens]\ntest_sarc_ids  = [numericalize(t) for t in test_sarc_tokens]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:21:34.907544Z","iopub.execute_input":"2025-08-24T08:21:34.907836Z","iopub.status.idle":"2025-08-24T08:21:50.603819Z","shell.execute_reply.started":"2025-08-24T08:21:34.907811Z","shell.execute_reply":"2025-08-24T08:21:50.602900Z"}},"outputs":[{"name":"stdout","text":"Combined Vocab size: 56617\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# %% [code]\nclass TextDS(Dataset):\n    def __init__(self, seqs, labels):\n        self.seqs = seqs\n        self.labels = torch.tensor(labels, dtype=torch.float32)\n    def __len__(self): return len(self.labels)\n    def __getitem__(self, i): return self.seqs[i], self.labels[i]\n\ndef collate(batch):\n    xs, ys = zip(*batch)\n    xs_pad = pad_sequence(xs, batch_first=True, padding_value=pad_idx)\n    mask = xs_pad.ne(pad_idx)\n    y = torch.stack(ys)\n    return xs_pad, mask, y\n\nBATCH = 64\n# We set num_workers=0 to avoid harmless multiprocessing errors in notebooks\ntrain_loader = DataLoader(TextDS(train_ids, train_labels), batch_size=BATCH, shuffle=True, collate_fn=collate, num_workers=0)\ntest_loader  = DataLoader(TextDS(test_ids,  test_labels),  batch_size=BATCH, shuffle=False, collate_fn=collate, num_workers=0)\ntrain_sarc_loader = DataLoader(TextDS(train_sarc_ids, train_sarc_labels), batch_size=BATCH, shuffle=True, collate_fn=collate, num_workers=0)\ntest_sarc_loader  = DataLoader(TextDS(test_sarc_ids,  test_sarc_labels),  batch_size=BATCH, shuffle=False, collate_fn=collate, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:22:03.091441Z","iopub.execute_input":"2025-08-24T08:22:03.092139Z","iopub.status.idle":"2025-08-24T08:22:03.114467Z","shell.execute_reply.started":"2025-08-24T08:22:03.092113Z","shell.execute_reply":"2025-08-24T08:22:03.113456Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# %% [code]\nimport glob # <-- ADD THIS LINE\n\ndef find_glove():\n    # Adjusted pattern to specifically find the 50d version you're using\n    for pat in [\"**/glove.6B.50d.txt\", \"**/glove.6B.*.txt\", \"**/glove.*.txt\"]:\n        for p in glob.glob(os.path.join(\"/kaggle/input\", pat), recursive=True):\n            return p\n    return None\n\ndef load_glove_as_embedding(word_to_idx, pad_idx, embedding_dim=None):\n    glove_path = find_glove()\n    if glove_path is None:\n        print(\"No GloVe found; using random embeddings.\")\n        # Default to a reasonable dimension if none is found or provided\n        dim = embedding_dim or 100 \n        return nn.Embedding(len(word_to_idx), dim, padding_idx=pad_idx)\n    \n    print(f\"Using GloVe: {glove_path}\")\n    # Automatically determine embedding_dim from the filename\n    if embedding_dim is None:\n        m = re.search(r\"\\\\.(\\\\d+)d\\\\.txt$\", glove_path)\n        embedding_dim = int(m.group(1)) if m else 300\n    \n    mat = np.random.randn(len(word_to_idx), embedding_dim).astype(np.float32) * 0.5 / embedding_dim\n    mat[pad_idx] = 0.0\n    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            parts = line.rstrip().split(\" \")\n            if len(parts) != embedding_dim + 1: continue\n            word, vec = parts[0], parts[1:]\n            if word in word_to_idx:\n                mat[word_to_idx[word]] = np.asarray(vec, dtype=np.float32)\n                \n    return nn.Embedding.from_pretrained(torch.tensor(mat), freeze=False, padding_idx=pad_idx)\n\n# Let the function determine the embedding dimension automatically from the file\nembedding = load_glove_as_embedding(word_to_idx, pad_idx).to(device)\nprint(\"Embedding dim:\", embedding.embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:25:56.631707Z","iopub.execute_input":"2025-08-24T08:25:56.632291Z","iopub.status.idle":"2025-08-24T08:26:01.022370Z","shell.execute_reply.started":"2025-08-24T08:25:56.632267Z","shell.execute_reply":"2025-08-24T08:26:01.021745Z"}},"outputs":[{"name":"stdout","text":"Using GloVe: /kaggle/input/glove6b50dtxt/glove.6B.50d.txt\nEmbedding dim: 300\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# %% [code]\nclass AttentionPool(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.proj = nn.Linear(in_dim, in_dim)\n        self.v = nn.Linear(in_dim, 1, bias=False)\n    def forward(self, H, mask=None):\n        S = torch.tanh(self.proj(H))\n        logits = self.v(S).squeeze(-1)\n        if mask is not None: logits = logits.masked_fill(~mask, -1e9)\n        w = torch.softmax(logits, dim=-1)\n        ctx = (H * w.unsqueeze(-1)).sum(1)\n        return ctx, w\n\nclass BiLSTMAttnMulti(nn.Module):\n    def __init__(self, embedding, hidden=256, p=0.4): # Tuned dropout\n        super().__init__()\n        self.embedding = embedding\n        self.dropout = nn.Dropout(p)\n        self.lstm = nn.LSTM(embedding.embedding_dim, hidden, batch_first=True, bidirectional=True)\n        self.attn = AttentionPool(2*hidden)\n        self.fc_sent = nn.Linear(2*hidden, 1)\n        self.fc_sarc = nn.Linear(2*hidden, 1)\n\n    def encode(self, x, mask):\n        E = self.dropout(self.embedding(x))\n        H, _ = self.lstm(E)\n        H = self.dropout(H)\n        ctx, w = self.attn(H, mask)\n        ctx = self.dropout(ctx)\n        return ctx, w\n\n    def forward(self, x, mask, task=\"sentiment\", return_attn=False):\n        ctx, w = self.encode(x, mask)\n        logits = self.fc_sent(ctx) if task == \"sentiment\" else self.fc_sarc(ctx)\n        if return_attn:\n            return logits.squeeze(-1), w\n        return logits.squeeze(-1)\n\nHIDDEN = 256\nmodel = BiLSTMAttnMulti(embedding=embedding, hidden=HIDDEN).to(device)\nprint(\"Model OK. Encoder out dim:\", 2*HIDDEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:26:14.757233Z","iopub.execute_input":"2025-08-24T08:26:14.757917Z","iopub.status.idle":"2025-08-24T08:26:14.887384Z","shell.execute_reply.started":"2025-08-24T08:26:14.757893Z","shell.execute_reply":"2025-08-24T08:26:14.886443Z"}},"outputs":[{"name":"stdout","text":"Model OK. Encoder out dim: 512\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# %% [code]\n# Tuned learning rate and increased epochs\nEPOCHS = 8\ncriterion = nn.BCEWithLogitsLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n@torch.no_grad()\ndef acc_from_logits(logits, y):\n    p = torch.sigmoid(logits)\n    return ((p >= 0.5).float() == y).float().mean()\n\ndef run_epoch_multitask(epoch, sar_loader):\n    model.train()\n    sar_iter = iter(sar_loader)\n    for xb, mb, yb in train_loader:\n        # Sentiment step\n        xb, mb, yb = xb.to(device), mb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        s_logits = model(xb, mb, task=\"sentiment\")\n        s_loss = criterion(s_logits, yb)\n        s_loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        # Sarcasm step\n        try: xs, ms, ys = next(sar_iter)\n        except StopIteration: sar_iter = iter(sar_loader); xs, ms, ys = next(sar_iter)\n        xs, ms, ys = xs.to(device), ms.to(device), ys.to(device)\n        optimizer.zero_grad()\n        z_logits = model(xs, ms, task=\"sarcasm\")\n        z_loss = criterion(z_logits, ys)\n        z_loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n    # Evaluation\n    model.eval()\n    with torch.no_grad():\n        s_loss, s_acc, s_n = 0., 0., 0\n        for xb, mb, yb in test_loader:\n            xb, mb, yb = xb.to(device), mb.to(device), yb.to(device)\n            logits = model(xb, mb, task=\"sentiment\")\n            s_loss += criterion(logits, yb).item() * yb.size(0)\n            s_acc  += acc_from_logits(logits, yb).item() * yb.size(0)\n            s_n += yb.size(0)\n        \n        t_loss, t_acc, t_n = 0., 0., 0\n        for xb, mb, yb in test_sarc_loader:\n            xb, mb, yb = xb.to(device), mb.to(device), yb.to(device)\n            logits = model(xb, mb, task=\"sarcasm\")\n            t_loss += criterion(logits, yb).item() * yb.size(0)\n            t_acc  += acc_from_logits(logits, yb).item() * yb.size(0)\n            t_n += yb.size(0)\n            \n    print(f\"Epoch {epoch:02d} | Sent val loss {s_loss/s_n:.4f} acc {s_acc/s_n:.4f} | \"\n          f\"Sarc val loss {t_loss/t_n:.4f} acc {t_acc/t_n:.4f}\")\n\n# Run training\nfor e in range(1, EPOCHS+1):\n    run_epoch_multitask(e, train_sarc_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T08:26:30.628838Z","iopub.execute_input":"2025-08-24T08:26:30.629368Z","iopub.status.idle":"2025-08-24T08:43:42.015447Z","shell.execute_reply.started":"2025-08-24T08:26:30.629345Z","shell.execute_reply":"2025-08-24T08:43:42.014682Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Sent val loss 0.2585 acc 0.8961 | Sarc val loss 0.6031 acc 0.6707\nEpoch 02 | Sent val loss 0.2722 acc 0.8939 | Sarc val loss 0.5934 acc 0.6815\nEpoch 03 | Sent val loss 0.2746 acc 0.8940 | Sarc val loss 0.5854 acc 0.6895\nEpoch 04 | Sent val loss 0.3611 acc 0.8858 | Sarc val loss 0.5814 acc 0.6926\nEpoch 05 | Sent val loss 0.3899 acc 0.8804 | Sarc val loss 0.5726 acc 0.7002\nEpoch 06 | Sent val loss 0.4025 acc 0.8827 | Sarc val loss 0.5706 acc 0.7013\nEpoch 07 | Sent val loss 0.5072 acc 0.8799 | Sarc val loss 0.5697 acc 0.7034\nEpoch 08 | Sent val loss 0.5215 acc 0.8784 | Sarc val loss 0.5669 acc 0.7052\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# %% [code]\ndef predict_texts_with_sarcasm(texts, mc_passes=30, sarcasm_threshold=0.5, uncertainty_tau=0.15):\n    # --- Get deterministic predictions ---\n    model.eval()\n    with torch.no_grad():\n        ids = [numericalize(tokenize(t)) for t in texts]\n        x = pad_sequence(ids, batch_first=True, padding_value=pad_idx).to(device)\n        mask = x.ne(pad_idx).to(device)\n        s_logits = model(x, mask, task=\"sentiment\")\n        sarc_logits = model(x, mask, task=\"sarcasm\")\n        s_probs = torch.sigmoid(s_logits).cpu().numpy()\n        sarc_probs = torch.sigmoid(sarc_logits).cpu().numpy()\n\n    # --- Get MC dropout uncertainty ---\n    model.train()\n    with torch.no_grad():\n        mc_probs = [torch.sigmoid(model(x, mask, task=\"sentiment\")) for _ in range(mc_passes)]\n        mc_probs = torch.stack(mc_probs)\n        mc_mean = mc_probs.mean(dim=0).cpu().numpy()\n        mc_std  = mc_probs.std(dim=0).cpu().numpy()\n    model.eval()\n\n    # --- Compile results ---\n    results = []\n    for txt, sp, sc, mm, ss in zip(texts, s_probs, sarc_probs, mc_mean, mc_std):\n        if ss > uncertainty_tau:\n            final_label = \"UNCERTAIN\"\n        elif sp >= 0.5 and sc >= sarcasm_threshold:\n            final_label = \"NEGATIVE (sarcastic flip)\"\n        elif sp >= 0.5:\n            final_label = \"POSITIVE\"\n        else:\n            final_label = \"NEGATIVE\"\n\n        results.append({\n            \"text\": txt,\n            \"sentiment_prob\": float(sp),\n            \"sarcasm_prob\": float(sc),\n            \"mc_mean\": float(mm),\n            \"mc_std\": float(ss),\n            \"final_label\": final_label\n        })\n    return results\n\n@torch.no_grad()\ndef show_attention(text, task=\"sentiment\", topk=10):\n    model.eval()\n    toks = tokenize(text)\n    ids = numericalize(toks).unsqueeze(0).to(device)\n    mask = ids.ne(pad_idx)\n    logits, w = model(ids, mask, task=task, return_attn=True)\n    \n    print(f\"\\nText: {text}\")\n    print(f\"Task: {task} | Probability: {torch.sigmoid(logits).item():.4f}\")\n    \n    pairs = sorted(zip(toks, w[0, :len(toks)].cpu().numpy()), key=lambda x: x[1], reverse=True)\n    for tok, wt in pairs[:topk]:\n        print(f\"{wt:.3f} {tok}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:09:08.105148Z","iopub.execute_input":"2025-08-24T09:09:08.105606Z","iopub.status.idle":"2025-08-24T09:09:08.114797Z","shell.execute_reply.started":"2025-08-24T09:09:08.105584Z","shell.execute_reply":"2025-08-24T09:09:08.114175Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# %% [code]\nsamples = [\n    \"This was one of the best movies I have ever seen, truly a masterpiece.\",\n    \"Well, that was two hours of my life I’ll never get back — but at least the popcorn was good.\",\n    \"This movie was absolutely fantastic... if you enjoy watching paint dry.\",\n    \"I just love waiting in line for hours, it’s the highlight of my day.\",\n    \"The acting was phenomenal and the storyline was captivating from start to finish.\",\n    \"The staff was rude and completely unhelpful when I tried to ask for assistance.\"\n]\n\n# Get final predictions\npredictions = predict_texts_with_sarcasm(samples)\nfor r in predictions:\n    print(\n        f\"\\\\nText: {r['text']}\\\\n\"\n        f\"  Sentiment Prob: {r['sentiment_prob']:.4f} | Sarcasm Prob: {r['sarcasm_prob']:.4f}\\\\n\"\n        f\"  MC Mean/Std: {r['mc_mean']:.4f} / {r['mc_std']:.4f} -> Final Label: {r['final_label']}\"\n    )\n\n# Visualize attention for a tricky sentence\nshow_attention(samples[1], task=\"sentiment\")\nshow_attention(samples[1], task=\"sarcasm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:15:56.973745Z","iopub.execute_input":"2025-08-24T09:15:56.974024Z","iopub.status.idle":"2025-08-24T09:15:57.019232Z","shell.execute_reply.started":"2025-08-24T09:15:56.974004Z","shell.execute_reply":"2025-08-24T09:15:57.018650Z"}},"outputs":[{"name":"stdout","text":"\\nText: This was one of the best movies I have ever seen, truly a masterpiece.\\n  Sentiment Prob: 0.9986 | Sarcasm Prob: 0.3369\\n  MC Mean/Std: 0.9984 / 0.0012 -> Final Label: POSITIVE\n\\nText: Well, that was two hours of my life I’ll never get back — but at least the popcorn was good.\\n  Sentiment Prob: 0.5626 | Sarcasm Prob: 0.3505\\n  MC Mean/Std: 0.5456 / 0.1549 -> Final Label: UNCERTAIN\n\\nText: This movie was absolutely fantastic... if you enjoy watching paint dry.\\n  Sentiment Prob: 0.0004 | Sarcasm Prob: 0.5080\\n  MC Mean/Std: 0.0008 / 0.0009 -> Final Label: NEGATIVE\n\\nText: I just love waiting in line for hours, it’s the highlight of my day.\\n  Sentiment Prob: 0.3084 | Sarcasm Prob: 0.4922\\n  MC Mean/Std: 0.3215 / 0.0623 -> Final Label: NEGATIVE\n\\nText: The acting was phenomenal and the storyline was captivating from start to finish.\\n  Sentiment Prob: 0.8708 | Sarcasm Prob: 0.1957\\n  MC Mean/Std: 0.8499 / 0.0883 -> Final Label: POSITIVE\n\\nText: The staff was rude and completely unhelpful when I tried to ask for assistance.\\n  Sentiment Prob: 0.1898 | Sarcasm Prob: 0.3988\\n  MC Mean/Std: 0.2028 / 0.0705 -> Final Label: NEGATIVE\n\nText: Well, that was two hours of my life I’ll never get back — but at least the popcorn was good.\nTask: sentiment | Probability: 0.5626\n0.216 ll\n0.097 get\n0.085 never\n0.068 popcorn\n0.068 back\n0.057 well\n0.045 two\n0.042 was\n0.042 the\n0.040 hours\n\nText: Well, that was two hours of my life I’ll never get back — but at least the popcorn was good.\nTask: sarcasm | Probability: 0.3505\n0.216 ll\n0.097 get\n0.085 never\n0.068 popcorn\n0.068 back\n0.057 well\n0.045 two\n0.042 was\n0.042 the\n0.040 hours\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}